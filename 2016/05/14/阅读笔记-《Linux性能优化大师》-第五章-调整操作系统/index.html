<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="keep it simple, stupid"><title> | dupengair的blog</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/3.0.3/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.5.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/2.2.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">dupengair的blog</h1><a id="logo" href="/.">dupengair的blog</a><p class="description">Less is more</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title"></h1><div class="post-meta">May 14, 2016<script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><div class="post-content"><hr>
<p>title: 第五章 调整操作系统<br>date: 2016-05-13 17:02:10<br>categories: [阅读笔记, 《Linux性能优化大师》]<br>tag: 《Linux性能优化大师》<br>toc: true</p>
<hr>
<hr>
<p>#调整操作系统</p>
<hr>
<ul>
<li>Linux 内存管理</li>
<li>系统清理</li>
<li>磁盘子系统优化</li>
<li>sysctl调整内核性能</li>
<li>网络优化</li>
</ul>
<p>#一、调整原则</p>
<ol>
<li>让系统适应特定的工作负载<ul>
<li>可能在不同的工作模式下表现不同，目的是让设备在最佳模式下运行</li>
</ul>
</li>
<li>一次只改变一个变量，记录生效的每一个参数并认真分析</li>
<li>重启可能提高性能的参数，统计和确认其影响效果</li>
</ol>
<p>#二、服务器环境</p>
<ol>
<li><p>安装</p>
<ul>
<li>技术选型<ul>
<li>处理器技术</li>
<li>磁盘技术</li>
<li>应用程序</li>
</ul>
</li>
<li>Linux版本选择<ul>
<li>企业版或定制发型版</li>
<li>支持的内核版本、软件包和特征等</li>
<li>硬件的支持水平</li>
</ul>
</li>
<li>内核版本的选择</li>
<li>分区布局的选择<ul>
<li>swap分区可提高性能，降低文件系统开销</li>
</ul>
</li>
<li>文件系统的选择<ul>
<li>延迟要求和吞吐量要求</li>
</ul>
</li>
<li>软件包选择<ul>
<li>最小化系统</li>
<li>降低安全威胁</li>
</ul>
</li>
<li>Netfilter配置<ul>
<li>过于复杂的防火墙规则会在高数据流量环境中降低性能</li>
</ul>
</li>
<li>SELinux<ul>
<li>通过SELinux提供额外安全会带来明显的性能损失</li>
</ul>
</li>
<li>运行级别选择<ul>
<li>图形级别5开销大</li>
<li>命令级别3适合服务器</li>
</ul>
</li>
</ul>
</li>
<li><p>检查当前配置</p>
<ul>
<li>CPU<ul>
<li>CPU模式、处理器架构、主板芯片</li>
<li>核心数量，是否支持超线程</li>
<li>主板socket数量，如何连接，数据速率(QPI、HyperTransport、FSB)</li>
<li>CPU每个层级的cache、cache是核心私有还是与其它核共享，以及在socket间共享，cache的组织和访问形式</li>
<li>处理器位数与支持的特征，如硬件虚拟化或特殊指令等</li>
</ul>
</li>
<li>内存<ul>
<li>内存大小，系统支持大雪</li>
<li>使用的内存技术，带宽和延迟</li>
<li>内存的物理连接，使用北桥和前端总线，还是直接连到CPU</li>
<li>是SMP还是NUMA，NUMA节点使用的技术以及访问不同区域时的影响</li>
</ul>
</li>
<li>存储<ul>
<li>存储设备的类型(HDD,SSD)</li>
<li>HDD的寻道时间、旋转延迟，访问不同分区的速度差异</li>
<li>期望的最大带宽和延迟</li>
<li>SSD的闪存类型(MLC/SLC)，是否支持TRIM，耐久性和垃圾收集系统的测量</li>
<li>磁盘阵列的级别，一个阵列里的存储设备数量，条带级别的每个条带大小</li>
<li>存储设备的连接技术(SATA/SAS)，带宽是否满足</li>
</ul>
</li>
<li>网络<ul>
<li>网卡性能，网络类型</li>
<li>应用场合与能力要求</li>
</ul>
</li>
</ul>
</li>
<li><p>了解系统能力</p>
<ul>
<li><p>查看内核消息</p>
<ul>
<li>传递内核信息的方式<ul>
<li>/proc文件系统</li>
<li>/sys文件系统</li>
<li>内核消息</li>
</ul>
</li>
<li>内核消息的传递过程<ul>
<li>klogd进程监听，并转发到syslog日志库</li>
<li>默认保存在/var/log/message下</li>
<li>可以通过dmesg打印出缓冲区内容</li>
</ul>
</li>
<li>查看dmesg的目的<ul>
<li>启动信息</li>
<li>硬件连接和检测信息</li>
<li>警告和错误信息</li>
</ul>
</li>
</ul>
</li>
<li><p>查看CPU信息</p>
<ul>
<li><p>通过lscpu获得概要</p>
<pre><code>$ lscpu
Architecture:          i686
CPU op-mode(s):        32-bit
Byte Order:            Little Endian
CPU(s):                2
On-line CPU(s) list:   0,1
Thread(s) per core:    1
Core(s) per socket:    2
Socket(s):             1
Vendor ID:             GenuineIntel
CPU family:            6
Model:                 26
Stepping:              5
CPU MHz:               2800.160
BogoMIPS:              5600.32
L1d cache:             32K
L1i cache:             32K
L2 cache:              256K
L3 cache:              8192K
</code></pre></li>
<li><p>通过lscpu -p获得cache信息</p>
<pre><code>$ lscpu -p
# The following is the parsable format, which can be fed to other
# programs. Each different item in every column has an unique ID
# starting from zero.
# CPU,Core,Socket,Node,,L1d,L1i,L2,L3
0,0,0,,,0,0,0,0
1,1,0,,,0,0,0,0
</code></pre></li>
</ul>
</li>
</ul>
</li>
<li><p>最小化资源使用</p>
<ul>
<li>守护进程<ul>
<li>service命令</li>
</ul>
</li>
<li><p>运行级别</p>
<ul>
<li>不在服务器上启动图形界面，需要时通过startx启动</li>
<li><p>使用sunlevel确定当前级别</p>
<pre><code>dvr@EdgeOS_builder:~$ runlevel 
N 2
</code></pre></li>
<li><p>使用init命令切换级别</p>
<pre><code>init 3
</code></pre></li>
<li><p>Linux运行级别：</p>
<ul>
<li>0 halt (关闭)</li>
<li>1 Single user (单用户)</li>
<li>2 Multiuser, with out NFS (多用户，无网络)</li>
<li>3 Full multiuser (多用户，带网络)</li>
<li>4 Unused (未使用)</li>
<li>5 X11 (图形界面)</li>
<li>6 Reboot (不停重启)</li>
</ul>
</li>
</ul>
<ul>
<li>修改/etc/inittab设置默认级别</li>
</ul>
</li>
</ul>
</li>
<li><p>SELinux</p>
<ul>
<li>SELinux引入的强制访问策略客服了Linux标准自主访问模型的局限性</li>
<li>任何特定进程的安全漏洞，只影响分配给进程的资源，而不是整个系统</li>
<li>SELinux如果虚拟机般工作，检测权限的过程可导致10%的系统开销</li>
<li>对于边缘服务器是很有价值的</li>
<li>检查缓存的Linux Security Modules(LSM)的权限，是否超过默认的Access Vector Cache(AVC)512条目的大小</li>
<li>最长链的长度检查<code>/selinux/avc/hash_stats</code>超过10表示可能存在瓶颈，此时可调整<code>/selinux/avc/cache_threshold</code>到较高值</li>
</ul>
</li>
</ol>
<p>#三、更改内核参数</p>
<ul>
<li><p>例子 - 系统内存过量使用策略</p>
<pre><code># cat /proc/sys/vm/overcommit_moemory
  0
# echo 1&gt;/proc/sys/vm/overcommit_moemory
</code></pre><ul>
<li>0表示系统为应用程序分配内存前，总进行可用内存检查</li>
<li>改为1表示每次分配时不检查内存</li>
</ul>
</li>
<li><p>echo命令不对参数进行一致性检查</p>
</li>
<li>所有对内核的改动系统重启后丢失</li>
<li>推荐使用sysctl工具<br>&gt;</li>
</ul>
<ol>
<li><p>proc文件系统</p>
<ul>
<li>提供了联机状态下访问正在运行的内核的接口</li>
<li>内容<ul>
<li>数字：进程pid，从开始指向init进程</li>
<li>acpi：高级配置和电源接口，服务器一般禁用</li>
<li>bus：总线子系统信息</li>
<li>irq：子系统中断信息，可以在子目录中改变特定中断的cpu亲和力</li>
<li>net：网络接口的大量原始统计</li>
<li>sys：可调整的内核参数</li>
<li>ttytty：系统的虚拟终端以及它所连接的物理设备信息</li>
</ul>
</li>
</ul>
</li>
<li><p>存储参数的位置</p>
<ul>
<li>/proc/sys/abi：文件与应用程序二进制信息，可能为空</li>
<li>/proc/sys/debug：内核调试信息，可能为空</li>
<li>/proc/sys/dev：特定设备信息，可能为空</li>
<li>/proc/sys/fs：文件系统调优，包括文件句柄、inode、dentry和配额</li>
<li>/proc/sys/kernel：内核参数调优</li>
<li>/proc/sys/net：网络性能调优</li>
<li>/proc/sys/vm：内存管理、buffer和cache管理调优</li>
</ul>
</li>
<li><p>sysctl命令</p>
<ul>
<li>使用/proc/sys目录树的文件名做参数</li>
<li><p>sysctl会在修改前检查数据的一致性：<code>sysctl -w</code></p>
<pre><code>sysctl -w kernel.shmmax=68719476736
</code></pre></li>
<li><p>如果希望永久生效，可以编辑/etc/sysctl.conf文件，添加相应命令:</p>
<pre><code>kernel.shmmax=68719476736
</code></pre></li>
<li><p>使用<code>sysctl -p</code>命令可使配置文件生效</p>
</li>
</ul>
</li>
</ol>
<p>#四 调整CPU子系统</p>
<ol>
<li><p>调整进程优先级</p>
<pre><code>$ chrt     
chrt - manipulate real-time attributes of a process

Set policy:
    chrt [options] &lt;policy&gt; &lt;priority&gt; {&lt;pid&gt; | &lt;command&gt; [&lt;arg&gt; ...]}

Get policy:
    chrt [options] {&lt;pid&gt; | &lt;command&gt; [&lt;arg&gt; ...]}

Scheduling policies:
    -b | --batch         set policy to SCHED_BATCH
    -f | --fifo          set policy to SCHED_FIFO
    -i | --idle          set policy to SCHED_IDLE
    -o | --other         set policy to SCHED_OTHER
    -r | --rr            set policy to SCHED_RR (default)

Scheduling flags:
    -R | --reset-on-fork set SCHED_RESET_ON_FORK for FIFO or RR

Options:
    -a | --all-tasks     operate on all the tasks (threads) for a given pid
    -h | --help          display this help
    -m | --max           show min and max valid priorities
    -p | --pid           operate on existing given pid
    -v | --verbose       display status information
    -V | --version       output version information
</code></pre></li>
</ol>
<pre><code>* chrt -m 查看进程调度策略

        $ chrt -m
        SCHED_OTHER min/max priority    : 0/0
        SCHED_FIFO min/max priority     : 1/99
        SCHED_RR min/max priority       : 1/99
        SCHED_BATCH min/max priority    : 0/0
        SCHED_IDLE min/max priority     : 0/0

    + 这里有2个实时调度策略： SCHED_RR 和 SCHED_FIFO
</code></pre><ol>
<li><p>调整运行策略</p>
<pre><code># chrt -p  -f  10 $(pidof FwLoader)
pid 1144&apos;s current scheduling policy: SCHED_OTHER
pid 1144&apos;s current scheduling priority: 0
pid 1144&apos;s new scheduling policy: SCHED_FIFO
pid 1144&apos;s new scheduling priority: 10 
</code></pre><ul>
<li><p>调度策略：</p>
<ul>
<li><code>SCHED_RR</code>：轮询调度(实时)，相同优先级轮询调度，只允许在一个最大时间片内运行</li>
<li><code>SCHED_FIFO</code>：先进先出(实时)，一直运行到IO阻塞，然后被号优先级进程抢占</li>
<li><code>SCHED_NORMAL</code>：标准轮询风格的时间共享策略(非实时)</li>
<li><code>SCHED_BATCH</code>：为批处理设计，几乎不抢占(非实时)</li>
<li><code>SCHED_IDLE</code>：用于运行非常低优先级的程序(非实时)</li>
</ul>
</li>
<li><p>改SCHED_NORMAL的优先级，用nice或renice命令，默认为0</p>
<ul>
<li><p>nice指定级别运行程序：</p>
<pre><code>nice -n 5 ./FwLoader
</code></pre></li>
<li><p>renice更改已运行的程序级别</p>
<pre><code>renice 10 $(pidof FwLoader)
</code></pre></li>
<li><p>更改程序的nice级到负数(提高优先级)，需要root级别</p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>CPU亲和力    </p>
<ul>
<li>CPU亲和力是为了把一个或多个进程绑定到一个或多个CPU核心上</li>
<li><p>taskset</p>
<ul>
<li>用于设置或检索进程的CPU亲和力，或者以某个亲和力运行进程</li>
<li><p>CPU亲和力表示为十六进制位掩码，每一位对应一个逻辑CPU</p>
<pre><code>cpu3 cpu2 cpu1 cpu0
 8    4    2    1
</code></pre></li>
<li><p>查看</p>
<pre><code># taskset -p $(pidof FwLoader)
pid 1095&apos;s current affinity mask: 3
</code></pre></li>
<li><p>设置</p>
<pre><code># taskset -p 2 $(pidof FwLoader)
pid 1095&apos;s current affinity mask: 3
pid 1095&apos;s new affinity mask: 2
</code></pre></li>
</ul>
</li>
</ul>
</li>
<li><p>平衡中断</p>
<ul>
<li><p>确定内核在哪个CPU上执行某个中断，可以查看/proc/irq/<irq-number>/smp_affinity</irq-number></p>
<pre><code># cat /proc/interrupts 
               CPU0       CPU1       
     29:   14979609    8411351       GIC  twd
     41:         75        110       GIC  ambarella-uart.0
     47:          0          0       GIC  ambarella-dma.0
     48:     117808     117474       GIC  fio_cmd_irq
    ....
    128:          0          0       GIC  vout0
    129:     159195     221475       GIC  vin0_vin
    136:     424874     336477       GIC  vout1
    137:        194        314       GIC  ambarella_hwtimer
    141:         51          0       GIC
    142:     362446     399002       GIC  vdsp
    143:     181362     199319       GIC  vcap
    144:     331678     429064       GIC  venc
    331:          0          0  ambarella gpio irq  ambarella-sd.1
    IPI0:          0          0  CPU wakeup interrupts
    ....
    Err:          0

# cat /proc/irq/144/smp_affinity
3
</code></pre><ul>
<li>位掩码为1表示对应cpu可以执行该中断</li>
</ul>
</li>
<li><p>守护进程irqbalance用于每隔一定时间调整一次中断的smp_affinity</p>
<pre><code>$ ps -ef |grep irq
root         3     2  0 Mar10 ?        00:02:15 [ksoftirqd/0]
root        10     2  0 Mar10 ?        00:00:25 [ksoftirqd/1]
root      1048     1  0 Mar10 ?        00:05:20 /usr/sbin/irqbalance
dvr      21669  1215  0 20:02 pts/3    00:00:00 grep --color=auto irq
</code></pre></li>
</ul>
</li>
<li><p>NUMA系统</p>
<ul>
<li>SMP拓扑<ul>
<li>早期多处理器系统基于SMP设计，每个CPU核通过共享总线访问RAM</li>
<li>容易构建，CPU可以快速访问所有内存地址，是统一的内存架构</li>
<li>由于共享总线架构，更多的处理器添加到系统以后，会产生瓶颈</li>
</ul>
</li>
<li>NUMA拓扑<ul>
<li>非统一内存架构，主存储器通过单独的总线直接连到单独的处理器或CPU封装</li>
<li>每个核仍能访问所有内存，但通过本地总线访问比远程总线快</li>
<li>一个程序在特定CPU上访问内存非常快，如果部分内存连接到其它处理器上，访问会非常慢</li>
<li>单socket系统可以基于一个NUMA进行有效的设计，因为只有一个NUMA节点，内存架构统一</li>
</ul>
</li>
</ul>
</li>
</ol>
<p>#五、调整内存子系统</p>
<p><strong>通过虚拟内存写入到文件系统cache，最终将数据刷出来</strong></p>
<ol>
<li><p>内存回收</p>
<ul>
<li><p>分页状态</p>
<pre><code>Free                分页有效，可立即分配
Inactive clean        分页没有活跃使用，内容与磁盘相符，自写入以来没有发生改变
Inactive dirty        分页没有活跃使用，内容已经发生修改，还没有被写回
Active                分页在活跃使用中，不可作为释放的候选
</code></pre></li>
<li><p>通过查看/proc/meminfo得到整个系统的内存分配，主要是Inactive(file)和Dirty</p>
</li>
<li>对每个进程可以查看<code>/proc/&lt;PID&gt;/smaps</code>，对每个内存段包含Shared/Clean以及脏数据大小</li>
<li>较早的内核使用pdflush处理脏数据，新内核被per-BDI flush线程处理</li>
<li><p>内核参数</p>
<pre><code>vm.dirty_expire_centisecs         经过多久脏数据写入磁盘(百分之一秒)
vm.dirty_writeback_centisecs    内核flush线程多久被唤醒一次写入数据，0为完全禁用周期性回写
vm.dirty_background_ratio        脏数据达到总内存的百分比，内核开始在后台回写数据
vm.dirty_ratio                    一个进程拥有的脏数据到达系统总内存的百分比，进程写出脏页
</code></pre></li>
<li><p>后两者可以代替<code>vm.dirty_bytes</code>和<code>vm.dirty_backgroud_bytes</code></p>
</li>
<li>较低的ratio适合交互式系统，较高的ratio适合少而大的写(总开销小)</li>
</ul>
</li>
<li><p>处理内存不足</p>
<ul>
<li>当一个次要页错误发生(minor page fault)，有没有空闲分页可用时，内核将尝试回收内存来满足请求，如果不能及时回收充足的内存，将出现Out-of-Memory的情况</li>
<li>默认情况下，内核会调用OOM Killer选择杀死一个或多个进程来释放内存</li>
<li>一旦出现OOM，就没有合理的选项来修复了，应尽量避免</li>
<li><p>内核为每个进程保存不良分数记录badness score，分数越高被杀的概率越大，在<code>/proc/&lt;PID&gt;/oom_score</code>查看</p>
<pre><code># cat /proc/1145/oom_score
60
# cat /proc/2141/oom_score
0
</code></pre></li>
<li>影响分数的因素：<ul>
<li>虚拟内存大小(包括子进程)</li>
<li>nice值(越大分越高)</li>
<li>总运行时间(越短分越高)</li>
<li>运行用户(root有轻微保护)</li>
<li>直接操作硬件分数降低</li>
</ul>
</li>
<li>内核本身和pid为1的进程(init)免疫</li>
<li>通过调整参数<code>/proc/&lt;PID&gt;/oom_adj</code>来手动调整oom_score<ul>
<li>值域：-17~15</li>
<li>0 不变</li>
<li>-17 免疫</li>
<li>当设置为负数时有较小机会被内核终结，设置为正数时更有可能被杀掉</li>
</ul>
</li>
</ul>
</li>
<li><p>调整swap</p>
<ul>
<li>默认swap分区位2倍物理RAM，位于不同的磁盘</li>
<li>swappiness<ul>
<li>内核释放内存分页，有两种选择<ul>
<li>从进程内存中换出一个分页</li>
<li>从分页cache中丢弃一个分页</li>
</ul>
</li>
<li>swap趋势(swap_tendency)<br>  <code>swap_tendency = mapped_ratio/2 + distress + vm_swappiness</code><ul>
<li>mapped_ratio是物理内存使用百分比</li>
<li>distress是衡量内核在释放内存中有多少开销，初始值为0，随尝试次数增加</li>
<li>vm_swappiness来自sysctl.swappiness</li>
</ul>
</li>
<li>swap_tendency低于100，内核从分页cache回收一个分页，高于100从进程空间中获得交换</li>
<li>调整vm.swapiness对系统影响较大<ul>
<li>设置为100，系统倾向于从page cache回收page，将有更多的内存分页cache使用，对IO密集型工作提高较大</li>
<li>设置为0，强制系统尽量减少swap，提高响应性能，但增加文件系统的开销</li>
</ul>
</li>
<li><code>/proc/sys/vm/swappiness</code>控制交换行为<ul>
<li>值越大越积极，越低越不积极</li>
<li>内存受限的情况下提高这个值比较有效</li>
</ul>
</li>
</ul>
</li>
<li><p>最优化swap空间</p>
<ul>
<li>swap的空间和位置对性能有很大影响<ul>
<li>机械硬盘上，盘片外部边缘的swap分区，吞吐量更好</li>
<li>SSD上性能好，但要考虑磨损</li>
</ul>
</li>
<li>配置额外的swap空间<ul>
<li>使用mkswap，划分空间分区，或者创建swap文件</li>
<li>创建swap分区具有性能优势，绕过了文件系统涉及文件操作的开销</li>
</ul>
</li>
<li><p>可以创建多个swap分区，以提供linux并行的读写，要在/etc/fstab包含</p>
<pre><code>#cat /etc/fstab
...
/dev/sda2 swap swap defauts 0 0
/dev/sda2 swap swap defauts 0 0
</code></pre><ul>
<li><p>可以使用挂载项pri=value来说明每个空间的优先级（0L~32767H）</p>
<pre><code>#cat /etc/fstab
...
/dev/sda2 swap swap defauts,pri=5 0 0
/dev/sda2 swap swap defauts,pri=5 0 0
</code></pre></li>
</ul>
</li>
</ul>
</li>
<li><p>保留swap空间的考量</p>
<pre><code>+ 始终把内存中不需要的分页移开，让物理内存做更多事情
+ 提供一个应急的保留区域以防止内存不足的情况
</code></pre></li>
<li><p>经验法则</p>
<pre><code>物理内存        建议swap最小空间
4G                2G
4~16G            4G
16~64G            8G
64~256G            16G
</code></pre></li>
</ul>
</li>
<li><p>HugeTLBfs</p>
<ul>
<li><p>概念</p>
<ul>
<li>进程请求内存时，保留虚拟内存地址，但在第一次使用之前不真正的映射到内存的物理分页</li>
<li>top与ps的区别：<ul>
<li>top：进程虚拟内存的总数量(VIRT和VSZ)</li>
<li>ps ：进程映射到物理内存的虚拟内存总数量(RES和RSS)，RSS更为重要，因为代表真实分配和映射的内存</li>
</ul>
</li>
<li>每个进程一个分页表，跟踪虚拟内存到物理内存的映射，每个虚拟分页一个条目</li>
<li>分页表被缓存在CPU旁路转换缓冲(Translation Lookaside Buffer, TLB)中，对进程进行调度，执行上下文切换时，必需经常刷新TLB条目</li>
</ul>
</li>
<li><p>Linux支持</p>
<ul>
<li><p>Linux通过hugepage机制支持超大分页，因此单个TLB条目可以映射更大的地址空间，以提高命中率</p>
<pre><code>$ cat /proc/meminfo 
MemTotal:        8266472 kB
MemFree:         6774932 kB
Buffers:          465988 kB
Cached:           577008 kB
SwapCached:         1888 kB
Active:           511872 kB
Inactive:         717528 kB
Active(anon):      51944 kB
Inactive(anon):   138824 kB
Active(file):     459928 kB
Inactive(file):   578704 kB
...
AnonHugePages:         0 kB
HugePages_Total:       0
HugePages_Free:        0
HugePages_Rsvd:        0
HugePages_Surp:        0
Hugepagesize:       2048 kB
...
</code></pre></li>
<li><p>可以通过sysctl命令配置/proc/sys/vm/nr_hugepages，来决定hugepage的数量</p>
<pre><code>$ sysctl -w vm.nr_hugepages=512
</code></pre></li>
<li><p>如果声明大于可用RAM的数量，会引起kernel panic</p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>内存同页合并</p>
<ul>
<li>当系统运行相同的工作时，内存分页很大几率会出现内容相同的情况，此时可以使用Kernel Samepage Merging(KSM)来合并完全相同的页，以减少总内存使用</li>
<li>服务：<ul>
<li>ksm 实际扫描内存并合并分页</li>
<li>ksmtuned 控制扫描策略和开关</li>
</ul>
</li>
<li><p>配置：</p>
<pre><code>$ ls -al /sys/kernel/mm/ksm/
total 0
...
full_scans        0    ：多长时间整个内存被扫描一次
pages_shared    0    ：被共享的物理分页数量
pages_sharing    0    ：被共享的逻辑分页数量
pages_to_scan    100    ：一个周期中扫描的分页数量
pages_unshared    0    ：
pages_volatile    0    ：
run                0    ：1使能，0禁用
sleep_millisecs    20    ：周期之间扫描的ms间隔
</code></pre></li>
<li>ksmtuned(略，服务器才有)</li>
</ul>
</li>
</ol>
<p>#六、调整磁盘子系统<br><em>磁盘访问以毫秒计算，比其它操作慢几千倍</em></p>
<ol>
<li><p>硬件安装</p>
<ul>
<li>驱动器数量<ul>
<li>通过RAID，可以分散IO到多个驱动器</li>
</ul>
</li>
<li>设置分区<ul>
<li>多分区的好处：<ul>
<li>更细粒度的提高文件系统的安全性</li>
<li>提高数据完整性</li>
<li>不影响其它多个静态分区的情况下进行升级</li>
<li>备份过程更高效</li>
</ul>
</li>
<li>分区参考<ul>
<li>/home<ul>
<li>分离用户主目录，对用户进行磁盘配额</li>
</ul>
</li>
<li>/tmp <ul>
<li>高性能环境中运行</li>
</ul>
</li>
<li>/usr <ul>
<li>内核源码树和Linux文档</li>
<li>所有用户访问的可执行文件</li>
<li>为环境开发的自定义脚本</li>
<li>升级时不用重新安装和部署</li>
</ul>
</li>
<li>/var<ul>
<li>环境和整个系统的日志记录</li>
<li>在邮件、网站、打印服务环境中很重要</li>
<li>长期使用可能被消息填满</li>
<li>可以进一步分离不同的分区</li>
</ul>
</li>
<li>/opt<ul>
<li>安装第三方软件，便于管理</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>IO调度的调整和选择</p>
<ul>
<li><p>选择正确的电梯算法</p>
<ul>
<li>同步文件系统访问<ul>
<li>CFQ和NOOP开始超过deadline，anticipatory最差</li>
</ul>
</li>
<li>复杂的磁盘子系统<ul>
<li>NOOP相同性能下开销较小</li>
</ul>
</li>
<li>数据库<ul>
<li>工作负载的定向搜索性</li>
<li>deadline性能增加</li>
</ul>
</li>
<li>虚拟机<ul>
<li>虚拟化层对IO重新排序</li>
</ul>
</li>
<li>CPU绑定应用程序<ul>
<li>NOOP有较小的CPU开销</li>
<li>多数异步文件系统下deadline和CFQ是最好的</li>
</ul>
</li>
</ul>
</li>
<li><p><code>nr_requests</code></p>
<ul>
<li>调整发送给磁盘子系统的请求数量</li>
<li>对Deadline比CFQ影响小</li>
<li>值调大，请求队列较大，能提高多次频繁的少量写操作，如日志</li>
<li><p>值调小，能使IO大小增加的情况下性能增加</p>
<pre><code>$ cat /sys/block/sda/queue/nr_requests
128 
</code></pre></li>
</ul>
</li>
<li><p><code>read_ahead_kb</code></p>
<ul>
<li>预读buffer大小，单位kb</li>
<li>大量的流读取下，增加大小会增加性能</li>
<li><p>对随机IO操作没有影响</p>
<pre><code>$ cat /sys/block/sda/queue/read_ahead_kb 
128
</code></pre></li>
</ul>
</li>
</ul>
</li>
<li><p>文件系统的选择和调整</p>
<ul>
<li><p>文件系统选择</p>
<ul>
<li>ReiserFS适合小而密集的IO<ul>
<li>文件、Web、邮件、日志服务器</li>
</ul>
</li>
<li>XFS和JFS适合大容量大吞吐IO的环境<ul>
<li>数据仓库、流媒体服务器</li>
</ul>
</li>
<li>Ext3中庸，适应小IO的同时提供良好扩展性</li>
<li>Ext2没有日志，注重性能而忽视数据完整性</li>
</ul>
</li>
<li><p>使用ionice分配IO优先级</p>
<ul>
<li><p>CFQ IO elevator提供ionice工具，可以在进程级别限制磁盘子系统使用率</p>
<pre><code>ionice -c 1 -p 689
-c&lt;#&gt;: IO优先级，1为real time，2为best effort， 3为idle
-n&lt;#&gt;: IO优先级0~7
-p&lt;#&gt;: pid
</code></pre></li>
<li><p>idle</p>
<ul>
<li>只有在没有其它(更高)优先级的进程请求访问数据时，才授权访问，最低</li>
</ul>
</li>
<li>best-effort<ul>
<li>默认所有不要求特定IO优先级的进程</li>
<li>进程继承各自CPU的nice优先级为8到IO优先级</li>
</ul>
</li>
<li>real time<ul>
<li>最高可用</li>
<li>总是在给定优先级下访问磁盘子系统</li>
<li>也可以设置为8，</li>
<li>应小心使用，可能导致其它任务等待</li>
</ul>
</li>
</ul>
</li>
<li><p>更新访问时间</p>
<ul>
<li>多数情况下，禁用文件访问时间更新只会带来非常小的性能提升</li>
<li>使用noatime挂载文件系统可以禁用访问时间更新</li>
<li>通常/var单独分区，使用noatime更新</li>
<li>/tmp通常不能禁用</li>
</ul>
</li>
<li><p>选择文件系统的日志模式</p>
<ul>
<li>使用mount的data命令设置</li>
<li>Ext3有较大影响</li>
<li>选项：<ul>
<li><code>data=journal</code><ul>
<li>通过将文件数据和元数据全部记录为日志来提供最高数据一致性</li>
<li>具有较高性能开销</li>
</ul>
</li>
<li><code>data=ordered</code><ul>
<li>只记录元数据，保证文件数据先写入</li>
<li>默认</li>
</ul>
</li>
<li><code>data=writeback</code><ul>
<li>在数据一致性代价下提供最快的数据访问</li>
<li>保证数据一致的前提下，记录元数据</li>
<li>没有对文件数据提供特殊处理，崩溃以后旧数据可能出现</li>
</ul>
</li>
</ul>
</li>
<li><p>更改日志模式：</p>
<ul>
<li><p>执行mount命令时：</p>
<pre><code>$ mount -o data=writeback /dev/sda1 /data
</code></pre></li>
<li><p>在/etc/fstab选项部分包含日志模式：</p>
<pre><code>/dev/sda1 /data ext3 defaults,data=writeback 0 0
</code></pre></li>
<li><p>在根分区上修改默认的data=ordered：</p>
<ul>
<li>修改/etc/fstab</li>
<li>执行mkinitrd命令，在/etc/fstab文件中扫描并创建新的镜像文件，更新GRUB或LILO指向新的镜像</li>
</ul>
</li>
</ul>
</li>
<li><p>块大小</p>
<ul>
<li>指从驱动中读取或写入数据的最小单位</li>
<li>如果处理大量小文件，小块更高效，反之亦然</li>
<li>不能联机改变，必需格式化分区</li>
<li>一般默认4K最好</li>
<li>RAID时，要指定条带大小stripe size，指驱动器存储数据的粒度</li>
<li>需要对照文件系统块大小，对整体磁盘性能有明显的影响<ul>
<li>对流和顺序内容，大的条带大小可以减少磁头寻道时间并提高吞吐量</li>
<li>对活跃的随机类型，如数据库，相当于记录大小的执行更有效 </li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>虚拟化存储</p>
</li>
</ol>
<p>#七、调整网络子系统</p>
<ol>
<li><p>网卡绑定</p>
<ul>
<li>通过bonding驱动程序，内核提供网络接口聚合    能力</li>
<li>bonding支持802.3链路聚合规范，可以实现复杂均衡和</li>
</ul>
</li>
<li><p>巨帧</p>
<ul>
<li>一个普通TCP包头40B，默认以太网标准MTU1500B，容量损失%2.7</li>
<li>减小开销的办法：<ul>
<li>切换协议<ul>
<li>UDP包头28B，损失小于%1.9</li>
<li>通常对业务不可行</li>
</ul>
</li>
<li>增加MTU<ul>
<li>在以太网标准的1500B下增加MTU，数据报称为巨帧Jumbo Frames</li>
<li>网络与网卡通常不支持，官方巨帧最大大小是9000B</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>速度与双工模式</p>
<ul>
<li>不匹配对性能有很大影响</li>
<li>通过自动协商，通常是被信任的</li>
<li>可以使用ethtool设置</li>
<li>速度和模式协商不正确时，对大数据的传输影响较大</li>
</ul>
</li>
<li><p>增加网络协议栈缓冲区</p>
<pre><code>基于系统内存自动计算的初始化tcp内存
# cat /proc/sys/net/ipv4/tcp_mem 
14154   18872   28308
接收socket内存的默认值和最大值
# cat /proc/sys/net/core/rmem_default 
163840
# cat /proc/sys/net/core/rmem_max 
163840
发送socket内存的默认值和最大值
# cat /proc/sys/net/core/wmem_default 
163840
# cat /proc/sys/net/core/wmem_max 
163840
可选内存buffers的最大值
# cat /proc/sys/net/core/optmem_max 
10240
</code></pre><ul>
<li><p>调整窗口大小</p>
<ul>
<li><p>理论上最优窗口大小为带宽延时乘积BDP，此时带宽利用最充分</p>
<pre><code>BDP(Bandwith Delay Product) = Bandwidth(bytes/sec) * Delay(or RTT sec)        
</code></pre></li>
<li><p>如果buffer与BDP不一致，发送端会等待确认</p>
</li>
<li>如果buffer太大会造成缓冲膨胀，严重影响小数据服务的速度和延时，如http、ssh</li>
<li><p>计算最大吞吐量所需的buffer：</p>
<ul>
<li><p>通过ping找出rtt</p>
<pre><code># ping 10.82.16.243
PING 10.82.16.243 (10.82.16.243): 56 data bytes
64 bytes from 10.82.16.243: seq=0 ttl=64 time=2.289 ms
64 bytes from 10.82.16.243: seq=1 ttl=64 time=1.318 ms
64 bytes from 10.82.16.243: seq=2 ttl=64 time=1.182 ms
64 bytes from 10.82.16.243: seq=3 ttl=64 time=1.525 ms
64 bytes from 10.82.16.243: seq=4 ttl=64 time=1.053 ms
^C
--- 10.82.16.243 ping statistics ---
5 packets transmitted, 5 packets received, 0% packet loss
round-trip min/avg/max = 1.053/1.473/2.289 ms
</code></pre><ul>
<li><p>对于100M网</p>
<pre><code>BDP = 10^6 * 0.001473 = 1473B = 1.473K
</code></pre></li>
</ul>
</li>
</ul>
</li>
<li><p>最大窗口限制为64K</p>
<ul>
<li><p>通过sysctl调整</p>
<pre><code># cat /proc/sys/net/ipv4/tcp_window_scaling 
1
</code></pre></li>
</ul>
</li>
<li><p>对于处理并发连接的情况，每个socket缓冲区大小只要能处理单个socket的BDP</p>
</li>
<li><p>设置最大接收和发送最大buffer：</p>
<pre><code># sysctl -w net.core.wmem_max=8388608
net.core.wmem_max = 8388608
# sysctl -w net.core.rmem_max=8388608
net.core.rmem_max = 8388608
</code></pre></li>
<li><p>设置发送和接收buffer(最小、初始、最大)：</p>
<pre><code># sysctl -w net.ipv4.tcp_wmem=&quot;4096 87380 8388608&quot;
net.ipv4.tcp_wmem = 4096 87380 8388608
# sysctl -w net.ipv4.tcp_rmem=&quot;4096 87380 8388608&quot;
net.ipv4.tcp_rmem = 4096 87380 8388608
</code></pre><ul>
<li>最大值要小于最大buffer大小</li>
<li>高速高质网络中增加最小值，使开始窗口较高</li>
</ul>
</li>
<li><p>增加分配给tcp的最小、压力、最大内存 </p>
<pre><code>/proc/sys/net/ipv4/tcp_mem
</code></pre><ul>
<li>如果buffer过小，会导致窗口小，频繁的ack确认，降低效率</li>
</ul>
</li>
</ul>
</li>
<li><p>socket buffer大小的影响</p>
<ul>
<li>大量大文件并发传输时，过小的socket buffer会导致性能下降</li>
<li>可调整<code>rmem_max</code>和<code>wmem_max</code></li>
</ul>
</li>
</ul>
</li>
<li><p>增加数据包队列</p>
<ul>
<li>增加数据包队列长度，可以使数据包在内核中保存时间更长</li>
<li><p>可以调整/proc/sys/net/core/netdev_max_backlog</p>
<pre><code># cat  /proc/sys/net/core/netdev_max_backlog 
1000
</code></pre></li>
</ul>
</li>
<li><p>增加传输队列长度</p>
<ul>
<li><p>高速连接进行大量均匀的数据传输时，增加接口的txqueuelength到100~20000之间可以提高性能</p>
<pre><code>$ ip link show dev eth0
2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UNKNOWN qlen 2000
    link/ether 00:50:56:3a:16:66 brd ff:ff:ff:ff:ff:ff
$ sudo ip link set eth0 txqueuelen 5000
$ ip link show dev eth0
2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UNKNOWN qlen 5000
    link/ether 00:50:56:3a:16:66 brd ff:ff:ff:ff:ff:ff
</code></pre></li>
</ul>
</li>
<li><p>配置ethtool</p>
<ul>
<li>一些网络操作可以从网络接口设备设置offload，从而减低CPU消耗</li>
<li>网络性能会有略微下降</li>
</ul>
</li>
<li><p>Netfilter对性能的影响</p>
<ul>
<li>Netfilter提高连接跟踪和数据包过滤，可能对性能产生较大影响，是安全性和性能之间的权衡</li>
<li>性能影响取决于：<ul>
<li>规则数量</li>
<li>规则顺序</li>
<li>规则复杂性</li>
<li>连接跟踪级别(取决于协议)</li>
<li>内核参数配置</li>
</ul>
</li>
</ul>
</li>
<li><p>流量特性</p>
<ul>
<li>流量特性影响性能的主要原因是，TCP会话的连接、关闭的开销</li>
<li>流量特性的要求：<ul>
<li>事务吞吐量的要求(峰值、均值)</li>
<li>数据传输吞吐量的要求(峰值、均值)</li>
<li>延迟的要求</li>
<li>传输数据的大小</li>
<li>发送和接收的比例</li>
<li>连接建立和关闭的频率或并发连接的数量</li>
<li>传输协议(UDP、TCP)和应用层协议(HTTP、SMTP)</li>
</ul>
</li>
</ul>
</li>
<li><p>额外的TCP/IP调整</p>
<ul>
<li><p>调整IP和ICMP行为</p>
<ul>
<li><p>禁用以下参数防止黑客对服务器IP地址进行欺骗攻击</p>
<pre><code># sysctl -w net.ipv4.conf.eth0.accept_source_route=0
net.ipv4.conf.eth0.accept_source_route = 0
# sysctl -w net.ipv4.conf.lo.accept_source_route=0  
net.ipv4.conf.lo.accept_source_route = 0
# sysctl -w net.ipv4.conf.default.accept_source_route=0
net.ipv4.conf.default.accept_source_route = 0
# sysctl -w net.ipv4.conf.all.accept_source_route=0    
net.ipv4.conf.all.accept_source_route = 0
</code></pre></li>
<li><p>配置服务器忽略来之被列出为网关机器的重定向。重定向可以进行攻击，配置只希望允许来自受信任的源</p>
<pre><code># sysctl -w net.ipv4.conf.eth0.secure_redirects=1 
net.ipv4.conf.eth0.secure_redirects = 1
# sysctl -w net.ipv4.conf.lo.secure_redirects=1  
net.ipv4.conf.lo.secure_redirects = 1
# sysctl -w net.ipv4.conf.default.secure_redirects=1
net.ipv4.conf.default.secure_redirects = 1
# sysctl -w net.ipv4.conf.all.secure_redirects=1    
net.ipv4.conf.all.secure_redirects = 1
</code></pre></li>
<li><p>可以禁用ICMP重定向。重定向用于路由器传达路由信息到主机，当网关收到主机的数据报时，可以发重定向给主机。网关检查路由表得到下一个网关地址，通过这个网关将数据报路由到网络。</p>
<pre><code># sysctl -w net.ipv4.conf.eth0.accept_redirects=0 
net.ipv4.conf.eth0.accept_redirects = 0
# sysctl -w net.ipv4.conf.lo.accept_redirects=0  
net.ipv4.conf.lo.accept_redirects = 0
# sysctl -w net.ipv4.conf.default.accept_redirects=0
net.ipv4.conf.default.accept_redirects = 0
# sysctl -w net.ipv4.conf.all.accept_redirects=0    
net.ipv4.conf.all.accept_redirects = 0
</code></pre></li>
<li><p>如果服务器不充当路由器，不用发送重定向，可以禁用：</p>
<pre><code># sysctl -w net.ipv4.conf.eth0.send_redirects=0  
net.ipv4.conf.eth0.send_redirects = 0
# sysctl -w net.ipv4.conf.lo.send_redirects=0  
net.ipv4.conf.lo.send_redirects = 0
# sysctl -w net.ipv4.conf.default.send_redirects=0
net.ipv4.conf.default.send_redirects = 0
# sysctl -w net.ipv4.conf.all.send_redirects=0    
net.ipv4.conf.all.send_redirects = 0
</code></pre></li>
<li><p>忽略广播ping和smurf攻击</p>
<pre><code># sysctl -w net.ipv4.icmp_echo_ignore_broadcasts=1
net.ipv4.icmp_echo_ignore_broadcasts = 1
</code></pre></li>
<li><p>忽略所有icmp类型的数据包或ping</p>
<pre><code># sysctl -w net.ipv4.icmp_echo_ignore_broadcasts=1
net.ipv4.icmp_echo_ignore_broadcasts = 1
</code></pre></li>
<li><p>忽略路由器发的无效响应广播帧，以免引起内核记录告警</p>
<pre><code># sysctl -w net.ipv4.icmp_echo_ignore_broadcasts=1
net.ipv4.icmp_echo_ignore_broadcasts = 1
</code></pre></li>
<li><p>设置ipfrag参数，用于重组IP碎片的最大和最小内存，在TCP传输中碎片发生错误时，数据存储在内存中被重传</p>
<pre><code># sysctl  -w  net.ipv4.ipfrag_low_thresh=262144
net.ipv4.ipfrag_low_thresh = 262144
# sysctl  -w  net.ipv4.ipfrag_high_thresh=393216
net.ipv4.ipfrag_high_thresh = 393216
</code></pre></li>
</ul>
</li>
<li><p>调整TCP的行为</p>
<ul>
<li><p>同时接收许多连接的服务器，如web服务器，TIME-WAIT sockets可以被新连接重新使用，以及TIME-WAIT状态的快速回收可以明显提高性能，因为TCP对每个连接维护一个cache</p>
<pre><code># sysctl  -w  net.ipv4.tcp_tw_reuse=1           
net.ipv4.tcp_tw_reuse = 1
# sysctl  -w  net.ipv4.tcp_tw_recycle=1
net.ipv4.tcp_tw_recycle = 1
</code></pre></li>
<li><p>可以缩短关闭socket时，出于FIN-WAIT-2状态的时间，但应仔细监控，因为由于死亡socket的数量，有内存溢出的风险</p>
<pre><code># sysctl -q net.ipv4.tcp_fin_timeout   
net.ipv4.tcp_fin_timeout = 60
# sysctl -w net.ipv4.tcp_fin_timeout=30
net.ipv4.tcp_fin_timeout = 30
</code></pre></li>
<li><p>缩短TCP保活定时器keepalive的时间，默认是2小时(7200S)</p>
<pre><code># sysctl -q net.ipv4.tcp_keepalive_time
net.ipv4.tcp_keepalive_time = 7200
# sysctl -w net.ipv4.tcp_keepalive_time=1800
net.ipv4.tcp_keepalive_time = 1800
</code></pre></li>
<li><p>增加允许的半连接的数量，可以避免服务器因为高延迟的不良客户端而负载过重，正常服务无法连接，还可以防止DoS flood攻击</p>
<pre><code># sysctl -q net.ipv4.tcp_max_syn_backlog
net.ipv4.tcp_max_syn_backlog = 128
# sysctl -w net.ipv4.tcp_max_syn_backlog=4096
net.ipv4.tcp_max_syn_backlog = 4096
</code></pre></li>
<li><p>TCP SYN cookies可以在DoS flood攻击中保护服务器，但可能对性能产生不良影响，只有在明确需要时才开启(需要内部编译时选择CONFIG_SYNCOOKIES选项)</p>
<pre><code>$ sysctl -w net.ipv4.tcp_syncookies=1
net.ipv4.tcp_syncookies = 1
</code></pre></li>
</ul>
</li>
<li><p>调整TCP选项</p>
<ul>
<li><p>默认开启优化TCP流量，对于高速网络，如在千兆网中，会影响性能，应关闭<code>tcp_sack</code>和<code>tcp_dsack</code></p>
<pre><code># sysctl -w net.ipv4.tcp_sack=0
net.ipv4.tcp_sack = 0
# sysctl -w net.ipv4.tcp_dsack=0
net.ipv4.tcp_dsack = 0
</code></pre></li>
<li><p>通过禁用以太网帧的时间戳，可以减少开销，尤其是对负担较重的核心服务器</p>
<pre><code># sysctl -w net.ipv4.tcp_timestamps=0
net.ipv4.tcp_timestamps = 0
</code></pre></li>
<li><p>系统遇到非常高的网络负载时，通常窗口缩放是不合适的，建议禁用窗口缩放和手动设置大小</p>
<pre><code># sysctl -w net.ipv4.tcp_window_scaling=0
net.ipv4.tcp_window_scaling = 0
</code></pre></li>
</ul>
</li>
</ul>
</li>
</ol>
<p>#八、限制资源使用</p>
<ol>
<li><p>ulimit</p>
<pre><code>ulimit -a 查看所有限制
       -H 设置硬件资源限制，一旦设置不能增加
       -S 设置软件资源限制，一旦设置允许增加，但不能超过硬件限制
</code></pre><ul>
<li>ulimit用于限制由shell启动的进程所占用的资源，同时支持硬资源和软资源</li>
<li><p>支持限制的资源：</p>
<ul>
<li>所创建的内核文件大小</li>
<li>进程数据块大小</li>
<li>shell创建的进程文件大小</li>
<li>内存锁住的大小</li>
<li>常驻内存集的大小</li>
<li>打开的文件描述符数量</li>
<li>分配堆栈的最大大小</li>
<li>CPU时间</li>
<li>单个用户的最大线程数</li>
<li>shell进程使用的最大虚拟内存</li>
</ul>
</li>
<li><p>查看当前状态：    </p>
<ul>
<li><p>设备：</p>
<pre><code># ulimit -a
time(seconds)        unlimited
file(blocks)         unlimited
data(kb)             unlimited
stack(kb)            unlimited
coredump(blocks)     0
memory(kb)           unlimited
locked memory(kb)    64
process              4697
nofiles              1024
vmemory(kb)          unlimited
locks                unlimited
</code></pre></li>
<li><p>虚拟机：</p>
<pre><code>$ ulimit -a
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 64468
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 1024
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 8192
cpu time               (seconds, -t) unlimited
max user processes              (-u) 64468
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited
</code></pre></li>
</ul>
</li>
<li><p>限制CPU时间</p>
<pre><code># ulimit -t 10
# ulimit -a | grep &quot;time&quot;
time(seconds)        10
</code></pre></li>
<li><p>限制虚拟内存</p>
<pre><code># ulimit -v 0
# ulimit -a | grep &quot;time&quot;
Killed
</code></pre></li>
<li><p>限制创建文件大小</p>
<pre><code># ulimit -f 10
# ulimit -a | grep file
file(blocks)         10
# dd if=/dev/zero of=file1 bs=1024 count=100
File size limit exceeded
</code></pre></li>
</ul>
</li>
<li><p><code>pam_limits</code></p>
<ul>
<li>使用<code>pam_limits.ko</code>资源限制模块</li>
<li>需要配置文件/etc/security/limits.conf</li>
<li><p>格式：</p>
<pre><code>#Each line describes a limit for a user in the form:
#
#&lt;domain&gt;        &lt;type&gt;  &lt;item&gt;  &lt;value&gt;
#Where:
#&lt;domain&gt; can be:
#        - an user name
#        - a group name, with @group syntax
#        - the wildcard *, for default entry
#        - the wildcard %, can be also used with %group syntax,
#                 for maxlogin limit
#        - NOTE: group and wildcard limits are not applied to root.
#          To apply a limit to the root user, &lt;domain&gt; must be
#          the literal username root.
#
#&lt;type&gt; can have the two values:
#        - &quot;soft&quot; for enforcing the soft limits
#        - &quot;hard&quot; for enforcing hard limits
#
#&lt;item&gt; can be one of the following:
#        - core - limits the core file size (KB)
#        - data - max data size (KB)
#        - fsize - maximum filesize (KB)
#        - memlock - max locked-in-memory address space (KB)
#        - nofile - max number of open files
#        - rss - max resident set size (KB)
#        - stack - max stack size (KB)
#        - cpu - max CPU time (MIN)
#        - nproc - max number of processes
#        - as - address space limit (KB)
#        - maxlogins - max number of logins for this user
#        - maxsyslogins - max number of logins on the system
#        - priority - the priority to run user process with
#        - locks - max number of file locks the user can hold
#        - sigpending - max number of pending signals
#        - msgqueue - max memory used by POSIX message queues (bytes)
#        - nice - max nice priority allowed to raise to values: [-20, 19]
#        - rtprio - max realtime priority
#        - chroot - change root to directory (Debian-specific)
#
#&lt;domain&gt;      &lt;type&gt;  &lt;item&gt;         &lt;value&gt;
#

#*               soft    core            0
#root            hard    core            100000
#*               hard    rss             10000
#@student        hard    nproc           20
#@faculty        soft    nproc           20
#@faculty        hard    nproc           50
#ftp             hard    nproc           0
#ftp             -       chroot          /ftp
#@student        -       maxlogins       4

# End of file

+ domain，可以是：
    - 一个用户名
    - 一个组名，语法是@group
    - 通配符*，定义默认条目
    - type，包括2个值：
        - hard，硬资源限制，由超级用户设定，由Linux内核实行，用户不能提升自己对资源的请求
        - soft，软资源限制，用户限制能在软硬限制之间上下浮动，这种限制在普通用法中可以看成是默认值
+ item，可以是：
    - core：限制core文件的大小(KB)
    - data：最大资料大小(KB)
    - fsize：最大文件尺寸(KB)
    - memlock：最大能锁定内存空间(KB)
    - nofile：最多能打开文件
    - rss：最大驻留程序大小(KB)
    - stack：最大堆栈尺寸(KB)
    - cpu：最大cpu时间(分钟)
    - nproc：最多的进程数
    - as：地址空间限制
    - maxlogins：用户的最多登陆数
    - priority：用户进程执行时的优先级
</code></pre><ul>
<li>pam_limits模块会通过syslog(3)报告它从设定中找到的问题</li>
</ul>
</li>
</ul>
</li>
</ol>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="http://yoursite.com/2016/05/14/阅读笔记-《Linux性能优化大师》-第五章-调整操作系统/" data-id="cio5y1v72006g92fyaql8tgyz" class="article-share-link">分享到</a><div class="tags"></div><div class="post-nav"><a href="/2016/05/14/阅读笔记-《http权威指南》-《http权威指南》阅读笔记/" class="pre"></a><a href="/2016/05/14/阅读笔记-《Linux性能优化大师》-第四章-分析性能瓶颈/" class="next"></a></div></div></div></div><div class="pure-u-1-4"><div id="sidebar"><div class="widget"><form action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://yoursite.com"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2016/05/14/阅读笔记-《高级C、C-编译技术》-《高级C、C-编译技术》阅读笔记/">阅读笔记-《高级C、C-编译技术》-《高级C、C-编译技术》阅读笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/05/14/阅读笔记-《面向模式的软件体系结构-卷1-模式系统》-《面向模式的软件体系结构-卷1-模式系统》/">阅读笔记-《面向模式的软件体系结构-卷1-模式系统》-《面向模式的软件体系结构-卷1-模式系统》</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/05/14/阅读笔记-《程序员的自我修养——链接、装载与库》-《程序员的自我修养——链接、装载与库》阅读笔记/">阅读笔记-《程序员的自我修养——链接、装载与库》-《程序员的自我修养——链接、装载与库》阅读笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/05/14/阅读笔记-《网络安全基础——网络攻防、协议与安全》-第一部分-网络概念与威胁入门/">阅读笔记-《网络安全基础——网络攻防、协议与安全》-第一部分-网络概念与威胁入门</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/05/14/阅读笔记-《网络安全基础——网络攻防、协议与安全》-第二部分-底层网络安全-第五章-物理层网络概述/">阅读笔记-《网络安全基础——网络攻防、协议与安全》-第二部分-底层网络安全-第五章-物理层网络概述</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/05/14/阅读笔记-《实战Linux-Shell-编程与服务器管理》-《实战Linux-Shell-编程与服务器管理》阅读笔记/">阅读笔记-《实战Linux-Shell-编程与服务器管理》-《实战Linux-Shell-编程与服务器管理》阅读笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/05/14/阅读笔记-《wireshark数据包分析实战》-《wireshark数据包分析实战》阅读笔记/">阅读笔记-《wireshark数据包分析实战》-《wireshark数据包分析实战》阅读笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/05/14/阅读笔记-《unix-网络编程-第三版》-附录-IPv4、IPv6、ICMPv4、ICMPv6/">阅读笔记-《unix-网络编程-第三版》-附录-IPv4、IPv6、ICMPv4、ICMPv6</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/05/14/阅读笔记-《unix-网络编程-第三版》-第十四章-高级IO/">阅读笔记-《unix-网络编程-第三版》-第十四章-高级IO</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/05/14/阅读笔记-《unix-网络编程-第三版》-第四章-基本TCP编程/">阅读笔记-《unix-网络编程-第三版》-第四章-基本TCP编程</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://easy.ac.cn/" title="easy" target="_blank">easy</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">dupengair的blog.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>